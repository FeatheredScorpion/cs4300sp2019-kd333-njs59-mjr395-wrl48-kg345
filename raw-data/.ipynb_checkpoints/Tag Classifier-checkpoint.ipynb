{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import time, datetime\n",
    "from collections import Counter\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "from sklearn import datasets, metrics\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.pipeline import make_pipeline, Pipeline, FeatureUnion\n",
    "from sklearn.preprocessing import FunctionTransformer, MultiLabelBinarizer\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
    "\n",
    "import os\n",
    "import json\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_json(\"tag-data.json\")\n",
    "datalist = data['drinks'].tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Bubbly', 'Fruity/Citrus-forward', 'Sweet', 'Dinner/Paired with food', 'Evening']\n"
     ]
    }
   ],
   "source": [
    "# preprocess tag data\n",
    "\n",
    "for drink in datalist:\n",
    "    flavors = drink['flavors']\n",
    "    if (len(drink['hours']) > 0):\n",
    "        flavors.extend(drink['hours'])\n",
    "    flavors.extend(drink['tags'])\n",
    "    if (len(drink['type']) > 0):\n",
    "        flavors.append(drink['type'])\n",
    "    ing = []\n",
    "    for i in drink['ingredients']:\n",
    "        ingredient = i[0] + ' ' + i[1]\n",
    "        ing.append(ingredient)\n",
    "    drink['ingredients'] = ing\n",
    "\n",
    "    \n",
    "print(datalist[0]['flavors'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2092, 6) (2092,)\n",
      "Counter({'Evening': 1443, 'Modern Classics': 1268, 'Sweet': 1062, 'Afternoon': 985, 'Fruity/Citrus-forward': 804, 'Spirit-forward': 572, 'Dinner/Paired with food': 424, 'Sour': 406, 'Summer': 350, 'Classics': 269, 'Bubbly': 259, 'Bitter': 221, 'Aperitif': 210, 'Winter': 207, 'Fall': 194, 'Spicy': 148, 'Creamy': 146, 'Morning/Brunch': 128, 'Spring': 122, 'Digestif': 120, 'Holiday Season': 106, 'Salty/Savory': 104, 'Tiki / Tropical': 91, 'Nightcap': 89, 'Brunch': 73, 'Hot': 64, 'Cinco de Mayo': 58, 'Christmas': 57, 'Punches': 53, 'Romantic': 43, 'Sports': 42, 'Frozen / Blended': 36, 'Thanksgiving': 34, 'Herbaceous': 33, 'Fourth of July': 31, \"St. Patrick's Day\": 27, 'Hanukkah': 26, 'Martinis': 26, 'Holiday party': 23, 'Margaritas': 22, \"Valentine's Day\": 22, 'Shots': 19, 'coffee': 17, 'Kentucky Derby': 17, 'Non-Alcoholic': 16, 'Burns Night': 13, 'Classics Martinis': 12, 'Mardi Gras': 12, \"Mother's Day\": 11, \"Father's Day\": 10, 'Classics Tiki / Tropical': 10, 'Classics Punches': 10, 'Margaritas Modern Classics': 9, 'Classics Hot': 9, 'Bastille Day': 9, 'Modern Classics Tiki / Tropical': 8, 'Martinis Modern Classics': 8, 'dessert': 8, 'Classics Modern Classics': 8, 'Valentine’s Day': 7, 'chocolate': 6, 'Punches Tiki / Tropical': 6, 'Super Bowl': 6, 'Tailgating': 6, 'New Years Eve': 5, 'Classics Margaritas': 4, \"April Fool's Day\": 4, 'Labor Day': 3, 'holidays': 3, 'Modern Classics Punches': 3, 'easter': 2, 'Luau': 2, 'Hot Modern Classics': 2, \"New Year's\": 2, 'Hot Punches': 2, 'Memorial Day': 2, 'winter': 1, 'Repeal Day': 1, 'Golden Globes': 1, 'Margaritas Punches': 1, 'Classics Shots': 1, 'World Cup': 1, 'Frozen / Blended Margaritas': 1, 'Travel': 1, 'summer': 1, 'Classics Frozen / Blended Punches': 1, 'Canada Day': 1, 'After-Dinner Drink': 1, 'Classics Frozen / Blended': 1, 'Dessert': 1, 'World Series': 1, 'Bourbon Heritage Month': 1, 'Modern Classics Shots': 1, 'Frozen / Blended Tiki / Tropical': 1, 'Halloween': 1, 'Classics Margaritas Punches': 1, 'Mexican Independence Day': 1, 'Classics Frozen / Blended Tiki / Tropical': 1, 'Classics Non-Alcoholic': 1, 'Presidents Day': 1, 'Nighttime': 1, 'Classics Hot Punches': 1, 'Spring Break': 1, 'breakfast': 1, 'Game of Thrones': 1}) 105\n"
     ]
    }
   ],
   "source": [
    "\n",
    "X = pd.DataFrame(datalist)\n",
    "y = X.pop('flavors')\n",
    "print(X.shape, y.shape)\n",
    "\n",
    "t = [x for row in y for x in row]\n",
    "flavors = Counter(t)\n",
    "print(flavors, len(flavors))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 ... 0 0 0]\n",
      " [1 0 0 ... 0 0 0]\n",
      " [1 0 0 ... 0 0 0]\n",
      " ...\n",
      " [1 0 0 ... 0 0 0]\n",
      " [1 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n",
      "(1882, 6) (1882, 101)\n",
      "Loaded: xTr (1882, 6) yTr (1882, 101) xTe (210, 6)\n",
      "Final Metadata Columns: ['ingredientCount']\n",
      "Processed: xTr_text (1882,) xTr_meta (1882, 1) yTr (1882, 101)\n"
     ]
    }
   ],
   "source": [
    "# data preprocessing\n",
    "yBin = mlb.fit_transform(y)\n",
    "print(yBin)\n",
    "xTr, xTe, yTr, yTe = train_test_split(X, yBin, test_size=0.10)\n",
    "\n",
    "print(xTr.shape, yTr.shape)\n",
    "print(\"Loaded:\",\"xTr\",xTr.shape,\"yTr\",yTr.shape,\"xTe\",xTe.shape)\n",
    "assert(xTr.shape[1] == xTe.shape[1])\n",
    "\n",
    "def preprocess_meta(xTr):\n",
    "    X = xTr.dropna(axis=1)\n",
    "    # X.loc[:,('created')] = pd.to_datetime(X.loc[:,'created']).dt.time.apply(lambda x: x.hour*60 + x.minute)\n",
    "    # X.loc[:,('has_link')] = X.loc[:,'text'].str.contains('http').astype(int)\n",
    "    X.loc[:,('ingredientCount')] = [ len(x) for x in X.loc[:,'ingredients'] ]\n",
    "        \n",
    "    return X[['ingredientCount']]\n",
    "\n",
    "# remove/replace useless text\n",
    "def preprocess_text(X):\n",
    "    # ingredient list to str and treat name as part of same doc\n",
    "    i = [ str(x[1]['name'] + ' ' + ' '.join(x[1]['ingredients'])) for x in X.iterrows() ]\n",
    "    \n",
    "    return np.array(i)\n",
    "\n",
    "# Preprocess the text data: get_text_data\n",
    "get_text_data = FunctionTransformer(\n",
    "    lambda x: preprocess_text(x),\n",
    "    validate=False\n",
    ")\n",
    "# Preprocess the numeric data: get_numeric_data\n",
    "get_meta_data = FunctionTransformer(\n",
    "    # use useful metadata and create/modify features from xTr cols\n",
    "    lambda x: preprocess_meta(x),\n",
    "    validate=False)\n",
    "print(\"Final Metadata Columns:\",list(get_meta_data.transform(xTr)))\n",
    "print(\"Processed:\",\n",
    "      \"xTr_text\",get_text_data.transform(xTr).shape,\n",
    "      \"xTr_meta\",get_meta_data.transform(xTr).shape,\n",
    "      \"yTr\",yTr.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model configuration\n",
    "\n",
    "# vectorize unlabeled testing and training data text\n",
    "vectorizer = TfidfVectorizer(\n",
    "    analyzer='word',\n",
    "    norm=None,\n",
    ")\n",
    "\n",
    "# default model\n",
    "default_model = LogisticRegression(solver='lbfgs', max_iter=1000); #best(?)\n",
    "# default_model = LinearSVC(max_iter=100000);\n",
    "# default_model = BernoulliNB()\n",
    "# default_model = RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "metadata": {
    "_uuid": "2d70b2734be94d775a4b6818c47ffc39e2095d2c"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/multiclass.py:76: UserWarning: Label not 20 is present in all training examples.\n",
      "  str(classes[c]))\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/multiclass.py:76: UserWarning: Label not 29 is present in all training examples.\n",
      "  str(classes[c]))\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/multiclass.py:76: UserWarning: Label not 53 is present in all training examples.\n",
      "  str(classes[c]))\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/multiclass.py:76: UserWarning: Label not 74 is present in all training examples.\n",
      "  str(classes[c]))\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in samples with no predicted labels.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/metrics/classification.py:1145: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in samples with no true labels.\n",
      "  'recall', 'true', average, warn_for)\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/multiclass.py:76: UserWarning: Label not 16 is present in all training examples.\n",
      "  str(classes[c]))\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/multiclass.py:76: UserWarning: Label not 32 is present in all training examples.\n",
      "  str(classes[c]))\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/multiclass.py:76: UserWarning: Label not 75 is present in all training examples.\n",
      "  str(classes[c]))\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/metrics/classification.py:1145: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in samples with no true labels.\n",
      "  'recall', 'true', average, warn_for)\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in samples with no predicted labels.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/multiclass.py:76: UserWarning: Label not 30 is present in all training examples.\n",
      "  str(classes[c]))\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/multiclass.py:76: UserWarning: Label not 43 is present in all training examples.\n",
      "  str(classes[c]))\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/multiclass.py:76: UserWarning: Label not 62 is present in all training examples.\n",
      "  str(classes[c]))\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/metrics/classification.py:1145: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in samples with no true labels.\n",
      "  'recall', 'true', average, warn_for)\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in samples with no predicted labels.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/multiclass.py:76: UserWarning: Label not 42 is present in all training examples.\n",
      "  str(classes[c]))\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/metrics/classification.py:1145: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in samples with no true labels.\n",
      "  'recall', 'true', average, warn_for)\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in samples with no predicted labels.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/multiclass.py:76: UserWarning: Label not 4 is present in all training examples.\n",
      "  str(classes[c]))\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/multiclass.py:76: UserWarning: Label not 52 is present in all training examples.\n",
      "  str(classes[c]))\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/multiclass.py:76: UserWarning: Label not 77 is present in all training examples.\n",
      "  str(classes[c]))\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in samples with no predicted labels.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/metrics/classification.py:1145: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in samples with no true labels.\n",
      "  'recall', 'true', average, warn_for)\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/multiclass.py:76: UserWarning: Label not 11 is present in all training examples.\n",
      "  str(classes[c]))\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/multiclass.py:76: UserWarning: Label not 50 is present in all training examples.\n",
      "  str(classes[c]))\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/multiclass.py:76: UserWarning: Label not 70 is present in all training examples.\n",
      "  str(classes[c]))\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/multiclass.py:76: UserWarning: Label not 96 is present in all training examples.\n",
      "  str(classes[c]))\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/multiclass.py:76: UserWarning: Label not 99 is present in all training examples.\n",
      "  str(classes[c]))\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/metrics/classification.py:1145: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in samples with no true labels.\n",
      "  'recall', 'true', average, warn_for)\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in samples with no predicted labels.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/multiclass.py:76: UserWarning: Label not 20 is present in all training examples.\n",
      "  str(classes[c]))\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/multiclass.py:76: UserWarning: Label not 29 is present in all training examples.\n",
      "  str(classes[c]))\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/multiclass.py:76: UserWarning: Label not 53 is present in all training examples.\n",
      "  str(classes[c]))\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/multiclass.py:76: UserWarning: Label not 74 is present in all training examples.\n",
      "  str(classes[c]))\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in samples with no predicted labels.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/metrics/classification.py:1145: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in samples with no true labels.\n",
      "  'recall', 'true', average, warn_for)\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/multiclass.py:76: UserWarning: Label not 16 is present in all training examples.\n",
      "  str(classes[c]))\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/multiclass.py:76: UserWarning: Label not 32 is present in all training examples.\n",
      "  str(classes[c]))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/multiclass.py:76: UserWarning: Label not 75 is present in all training examples.\n",
      "  str(classes[c]))\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/metrics/classification.py:1145: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in samples with no true labels.\n",
      "  'recall', 'true', average, warn_for)\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in samples with no predicted labels.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/multiclass.py:76: UserWarning: Label not 30 is present in all training examples.\n",
      "  str(classes[c]))\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/multiclass.py:76: UserWarning: Label not 43 is present in all training examples.\n",
      "  str(classes[c]))\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/multiclass.py:76: UserWarning: Label not 62 is present in all training examples.\n",
      "  str(classes[c]))\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/metrics/classification.py:1145: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in samples with no true labels.\n",
      "  'recall', 'true', average, warn_for)\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in samples with no predicted labels.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/multiclass.py:76: UserWarning: Label not 42 is present in all training examples.\n",
      "  str(classes[c]))\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/metrics/classification.py:1145: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in samples with no true labels.\n",
      "  'recall', 'true', average, warn_for)\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in samples with no predicted labels.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/multiclass.py:76: UserWarning: Label not 4 is present in all training examples.\n",
      "  str(classes[c]))\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/multiclass.py:76: UserWarning: Label not 52 is present in all training examples.\n",
      "  str(classes[c]))\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/multiclass.py:76: UserWarning: Label not 77 is present in all training examples.\n",
      "  str(classes[c]))\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in samples with no predicted labels.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/metrics/classification.py:1145: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in samples with no true labels.\n",
      "  'recall', 'true', average, warn_for)\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/multiclass.py:76: UserWarning: Label not 11 is present in all training examples.\n",
      "  str(classes[c]))\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/multiclass.py:76: UserWarning: Label not 50 is present in all training examples.\n",
      "  str(classes[c]))\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/multiclass.py:76: UserWarning: Label not 70 is present in all training examples.\n",
      "  str(classes[c]))\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/multiclass.py:76: UserWarning: Label not 96 is present in all training examples.\n",
      "  str(classes[c]))\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/multiclass.py:76: UserWarning: Label not 99 is present in all training examples.\n",
      "  str(classes[c]))\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/metrics/classification.py:1145: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in samples with no true labels.\n",
      "  'recall', 'true', average, warn_for)\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in samples with no predicted labels.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 0.7302828940945483\n",
      "Best params: {'union__text_features__vectorizer__max_features': 10000}\n",
      "Estimator: Pipeline(memory=None,\n",
      "     steps=[('union', FeatureUnion(n_jobs=None,\n",
      "       transformer_list=[('numeric_features', Pipeline(memory=None,\n",
      "     steps=[('selector', FunctionTransformer(accept_sparse=False, check_inverse=True,\n",
      "          func=<function <lambda> at 0x12d318400>, inv_kw_args=None,\n",
      "          inverse_func=None, kw_ar...e=None, solver='lbfgs',\n",
      "          tol=0.0001, verbose=0, warm_start=False),\n",
      "          n_jobs=None))])\n",
      "Pipeline time: 75.10644006729126\n"
     ]
    }
   ],
   "source": [
    "# add more features\n",
    "\n",
    "start_time=time.time()\n",
    "pipe = Pipeline([\n",
    "    ('union', FeatureUnion( # add both text and metadata to xTr\n",
    "        transformer_list = [\n",
    "            ('numeric_features', Pipeline([\n",
    "                ('selector', get_meta_data)\n",
    "            ])),\n",
    "            ('text_features', Pipeline([\n",
    "                ('selector', get_text_data),\n",
    "                ('vectorizer', vectorizer)\n",
    "            ]))\n",
    "        ]\n",
    "    )),\n",
    "    ('clf', OneVsRestClassifier(default_model))\n",
    "])\n",
    "\n",
    "param_grid = {'union__text_features__vectorizer__max_features': [10000, 30000],\n",
    "              # 'clf__estimator__C': [0.1, 1]\n",
    "             } \n",
    "grid = GridSearchCV(pipe, param_grid, cv=6, scoring='f1_samples')\n",
    "grid4 = grid.fit(xTr, yTr)\n",
    "\n",
    "print('Accuracy score:',grid4.best_score_)\n",
    "print('Best params:',grid4.best_params_)\n",
    "print('Estimator:',grid4.estimator)\n",
    "\n",
    "end_time=time.time()\n",
    "print(\"Pipeline time:\",end_time-start_time)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "metadata": {
    "_uuid": "97366346b72c100e85e495f8ff7d1689bf4031d1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                             hours  \\\n",
      "899                                             []   \n",
      "203   [Aperitif, Dinner/Paired with food, Evening]   \n",
      "1641                [Afternoon, Evening, Nightcap]   \n",
      "979                                      [Evening]   \n",
      "1349                          [Afternoon, Evening]   \n",
      "428                           [Afternoon, Evening]   \n",
      "823                                    [Afternoon]   \n",
      "456                                    [Afternoon]   \n",
      "1248                          [Afternoon, Evening]   \n",
      "805                                    [Afternoon]   \n",
      "\n",
      "                                            ingredients  \\\n",
      "899   [2 oz VEEV spirit, 1 oz Martini Bianco Vermout...   \n",
      "203   [2 oz Gin, 3⁄4 oz Orange curaçao, 1⁄2 oz Fresh...   \n",
      "1641  [3⁄4 oz Baileys Original Irish Cream, 1 3⁄4 oz...   \n",
      "979   [1 oz Tanqueray Bloomsbury gin, 1 oz Dolin dry...   \n",
      "1349  [1 1⁄2 oz Pistachio fat-washed vodka*, 1 1⁄2 o...   \n",
      "428   [1 oz Canadian whisky, 1 oz Sour apple schnapp...   \n",
      "823   [1 1⁄4 oz Aberlour 12-year-old scotch, 3⁄4 oz ...   \n",
      "456   [3 1⁄2 oz Dry white wine (such as grüner veltl...   \n",
      "1248  [2 oz Basil Hayden's Bourbon, 1⁄4 oz Nocello W...   \n",
      "805   [2 oz Espolón reposado tequila,  Del Maguey me...   \n",
      "\n",
      "                                name  \\\n",
      "899                      Martini 2.0   \n",
      "203                        Pegu Club   \n",
      "1641              Apple Irish Coffee   \n",
      "979   Room Temperature Martini No. 3   \n",
      "1349                        Cardamom   \n",
      "428                 Washington Apple   \n",
      "823        No Country for Orange Men   \n",
      "456                      Schnapsicle   \n",
      "1248                    Spiced Cocoa   \n",
      "805                Tequila Honey Bee   \n",
      "\n",
      "                                                    src            tags  \\\n",
      "899   cdn.liquor.com/wp-content/uploads/2014/07/mart...              []   \n",
      "203   cdn.liquor.com/wp-content/uploads/2011/10/pegu...              []   \n",
      "1641  cdn.liquor.com/wp-content/uploads/2014/04/reci...              []   \n",
      "979   cdn.liquor.com/wp-content/uploads/2017/07/2414...        [Spring]   \n",
      "1349  cdn.liquor.com/wp-content/uploads/2015/05/slid...              []   \n",
      "428   cdn.liquor.com/wp-content/uploads/2017/10/2014...        [Summer]   \n",
      "823   cdn.liquor.com/wp-content/uploads/2017/05/1809...              []   \n",
      "456   cdn.liquor.com/wp-content/uploads/2018/07/0914...        [Summer]   \n",
      "1248  cdn.liquor.com/wp-content/uploads/2015/11/1612...  [Fall, Winter]   \n",
      "805   cdn.liquor.com/wp-content/uploads/2019/01/2314...              []   \n",
      "\n",
      "                  type                                              label  \\\n",
      "899           Martinis  ( , C, Dinner/Paired with food, Evening, M, Sp...   \n",
      "203           Classics  ( , Afternoon, C, Dinner/Paired with food, Eve...   \n",
      "1641   Modern Classics                      (C, Creamy, Evening, a, c, s)   \n",
      "979           Classics  (C, Dinner/Paired with food, Evening, M, Spiri...   \n",
      "1349           Punches   (C, M, Salty/Savory, Spicy, a, c, i, l, n, r, s)   \n",
      "428    Modern Classics  (C, Evening, Fall, M, Sweet, a, c, d, e, i, l,...   \n",
      "823    Modern Classics  ( , C, Fruity/Citrus-forward, M, a, c, d, e, i...   \n",
      "456   Frozen / Blended                   ( , Summer, d, e, i, l, n, o, r)   \n",
      "1248               Hot  ( , C, Evening, Sweet, Winter, a, c, d, e, i, ...   \n",
      "805    Modern Classics  ( , C, Evening, M, Sweet, a, c, d, e, i, l, n,...   \n",
      "\n",
      "                                                 actual  \n",
      "899                               (M, a, i, n, r, s, t)  \n",
      "203   (Aperitif, C, Dinner/Paired with food, Evening...  \n",
      "1641  ( , Afternoon, C, Evening, M, Nightcap, Sweet,...  \n",
      "979   (C, Evening, Spirit-forward, Spring, a, c, i, ...  \n",
      "1349  (Afternoon, Bitter, Evening, P, Salty/Savory, ...  \n",
      "428   ( , Afternoon, C, Evening, Fruity/Citrus-forwa...  \n",
      "823   ( , Afternoon, C, M, Sour, a, c, d, e, i, l, n...  \n",
      "456   ( , /, Afternoon, B, F, Summer, Sweet, d, e, l...  \n",
      "1248  (Afternoon, Evening, Fall, H, Spicy, Sweet, Wi...  \n",
      "805   ( , Afternoon, C, M, Sweet, a, c, d, e, i, l, ...  \n",
      "precision: 0.7487021303507695\n",
      "recall: 0.7487733071638861\n",
      "f1score: 0.7406420531681335\n",
      "support: None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/metrics/classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "pred = grid4.predict(xTe)\n",
    "pred_inv = mlb.inverse_transform(pred)\n",
    "actual = mlb.inverse_transform(yTe)\n",
    "xTe = xTe.assign(label = pred_inv)\n",
    "xTe = xTe.assign(actual = actual)\n",
    "print(xTe[:10])\n",
    "\n",
    "\n",
    "precision, recall, fscore, support = metrics.precision_recall_fscore_support(yTe, pred, average='weighted')\n",
    "print('precision: {}'.format(precision))\n",
    "print('recall: {}'.format(recall))\n",
    "print('f1score: {}'.format(fscore))\n",
    "print('support: {}'.format(support))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "metadata": {
    "_uuid": "9ee369c3065c109f39dc426671331a2bcb8eca92"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        categories                                        description  \\\n",
      "0               []  Place one ice cube in the glass and add 1 1/2 ...   \n",
      "1               []  Fill a pint glass with ice. Pour vodka and cof...   \n",
      "2      [halloween]  Shake with ice and strain into chilled cocktai...   \n",
      "3               []  Bring all syrup ingredients to a boil in a sma...   \n",
      "4               []  In a blender, combine ice, rum, limeade concen...   \n",
      "5               []  Stir the orange juice, pineapple juice, simple...   \n",
      "6               []  Muddle the sugar into the lime wedges in an ol...   \n",
      "7               []  Cut half a lime into pieces, place in a shaker...   \n",
      "8      [afternoon]  Put ice cubes in collins glass and add lime vo...   \n",
      "9  [party, sports]  Rub rim of cocktail glass with rind of lemon o...   \n",
      "\n",
      "                                         ingredients  \\\n",
      "0  [1 1/2 oz  Advocaat, 8-10 oz cold  Lemonade, 1...   \n",
      "1  [ice cubes, or as needed, 2 fluid ounces vodka...   \n",
      "2  [1 oz  Blanco tequila, 3/4 oz  Blood orange li...   \n",
      "3  [Syrup:, 1 cup sugar, 1 cup water, 1/3 cup pac...   \n",
      "4  [1 cup ice, 1 cup light rum, 1/2 (6 ounce) can...   \n",
      "5  [2 cups fresh orange juice, 2 cups unsweetened...   \n",
      "6  [2 tsp  demerara Sugar, 1 Lime, 2 1/2 oz Cachaca]   \n",
      "7  [½ Lime, 2 tsp Brown sugar, 4 cl Passion fruit...   \n",
      "8              [2 oz  Lime Vodka,   Lemon-lime soda]   \n",
      "9  [2 oz  Tequila, 1 oz  Hot Shot Tropical Fruit ...   \n",
      "\n",
      "                            name            rating  \\\n",
      "0                       Snowball                -1   \n",
      "1              Chocolate Amnesia                 5   \n",
      "2                  Jinx Cocktail                -1   \n",
      "3       Rosemary-Ginger Cocktail  4.57142877578735   \n",
      "4                  Lime Daiquiri                 3   \n",
      "5  Bahama Mama Celebration Drink  3.33333325386047   \n",
      "6                Dark Caipirinha                -1   \n",
      "7                        Ipamena                -1   \n",
      "8                     Lime Giant                -1   \n",
      "9             Hot Shot Margarita                -1   \n",
      "\n",
      "                                             related  \\\n",
      "0  [{'score': 0.8580977009022827, 'name': 'Dolore...   \n",
      "1  [{'score': 0.8044678683517315, 'name': 'Silk S...   \n",
      "2  [{'score': 0.7206109482977048, 'name': 'D'arta...   \n",
      "3  [{'score': 0.7734438850322655, 'name': 'Frostb...   \n",
      "4  [{'score': 1.0, 'name': 'Italian Wedding Cake ...   \n",
      "5  [{'score': 0.9022785312971733, 'name': 'Carre ...   \n",
      "6  [{'score': 0.8035417513666415, 'name': 'Calimo...   \n",
      "7  [{'score': 0.894413221242371, 'name': 'Apple B...   \n",
      "8  [{'score': 0.818272269667349, 'name': 'Greyhou...   \n",
      "9  [{'score': 0.9969293267614558, 'name': 'Prom N...   \n",
      "\n",
      "                                             reviews  \\\n",
      "0                                                 []   \n",
      "1  [{'stars': '5', 'body': 'If you like white Rus...   \n",
      "2                                                 []   \n",
      "3  [{'stars': '4', 'body': 'Flavors are great, bu...   \n",
      "4  [{'stars': '4', 'body': 'I think the first rev...   \n",
      "5  [{'stars': '4', 'body': 'I cut this down to tw...   \n",
      "6                                                 []   \n",
      "7                                                 []   \n",
      "8                                                 []   \n",
      "9                                                 []   \n",
      "\n",
      "                                                 src  \\\n",
      "0  http://www.thecocktaildb.com/images/media/drin...   \n",
      "1  https://images.media-allrecipes.com/userphotos...   \n",
      "2  http://worldartsme.com/images/cocktail-glass-c...   \n",
      "3  https://images.media-allrecipes.com/userphotos...   \n",
      "4  https://images.media-allrecipes.com/userphotos...   \n",
      "5  https://images.media-allrecipes.com/userphotos...   \n",
      "6  http://www.thecocktaildb.com/images/media/drin...   \n",
      "7  http://www.thecocktaildb.com/images/media/drin...   \n",
      "8  http://worldartsme.com/images/cocktail-glass-c...   \n",
      "9  http://worldartsme.com/images/cocktail-glass-c...   \n",
      "\n",
      "                                                tags  \n",
      "0  ( , C, Evening, Fruity/Citrus-forward, M, Sour...  \n",
      "1      ( , C, Evening, M, a, c, d, e, i, l, o, r, s)  \n",
      "2  ( , Aperitif, C, Fruity/Citrus-forward, M, a, ...  \n",
      "3         (-, A, Fall, N, P, Summer, Sweet, h, n, u)  \n",
      "4  ( , /, Afternoon, B, F, Summer, d, e, l, n, o,...  \n",
      "5       (/, Fruity/Citrus-forward, Summer, Sweet, o)  \n",
      "6  ( , Afternoon, C, Dinner/Paired with food, Eve...  \n",
      "7  ( , Afternoon, C, Evening, Fruity/Citrus-forwa...  \n",
      "8  ( , Afternoon, C, Evening, M, Sour, Sweet, a, ...  \n",
      "9                 (Afternoon, H, Spicy, Sweet, o, t)  \n"
     ]
    }
   ],
   "source": [
    "# run on actual drink list\n",
    "with open('../app/static/drinks-with-related.json', 'r') as infile:  \n",
    "    jsonData = json.load(infile)\n",
    "    drinklst = jsonData['drinks']\n",
    "    drinks = pd.DataFrame(drinklst)\n",
    "    \n",
    "    pred = grid4.predict(drinks)\n",
    "    pred = mlb.inverse_transform(pred)\n",
    "    \n",
    "    drinks['tags'] = pred\n",
    "    print(drinks[:10])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [],
   "source": [
    "jsondata = {}\n",
    "jsondata['drinks'] = []\n",
    "for i, drink in drinks.iterrows():\n",
    "    try:\n",
    "        ing = [(b +\" \" + a) for (a,b) in drink['ingredients'] if a != \"\"]\n",
    "    except ValueError:\n",
    "        ing = [a for a in drink['ingredients'] if a != \"\"]\n",
    "        \n",
    "    if 'instructions' in drink:\n",
    "        drink['description'] = drink['instructions']\n",
    "    \n",
    "    jsondata['drinks'].append({\n",
    "        'name' : drink['name'],\n",
    "        'description' : drink['description'],\n",
    "        'src' : drink['src'],\n",
    "        'ingredients' : ing,\n",
    "        'rating' : drink['rating'],\n",
    "        'reviews' : drink.get('reviews', []),\n",
    "        'categories' : drink.get('categories', []),\n",
    "        'related' : drink.get('related', []),\n",
    "        'tags' : drink.get('tags', [])\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../app/static/drinks-with-related-and-tags.json', 'w') as outfile:  \n",
    "    json.dump(jsondata, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv2",
   "language": "python",
   "name": ".venv2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
